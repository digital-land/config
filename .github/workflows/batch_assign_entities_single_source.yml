name: Run Batch Assign (single-source), Upload Artifacts, Create PR, Cleanup

on:
  workflow_dispatch:

jobs:
  run-and-pr:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout repo
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Step 2: Checkout specification repo and copy into ./specification
      - name: Checkout specification
        uses: actions/checkout@v4
        with:
          repository: digital-land/specification
          path: specification-src
          fetch-depth: 1
          submodules: false

      - name: Prepare specification
        run: |
          rm -rf specification
          cp -r specification-src/specification specification
          rm -rf specification-src

      # Step 3: Prepare organisation cache (expected by script)
      - name: Prepare organisation cache
        run: |
          mkdir -p var/cache
          curl -sSL \
            https://raw.githubusercontent.com/digital-land/organisation-dataset/main/organisation.csv \
            -o var/cache/organisation.csv

      # Step 4: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      # Step 5: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Ensure digital-land-python is present (check_and_assign_entities)
          pip install git+https://github.com/digital-land/digital-land-python.git

          # Install repo requirements if present (avoid re-installing digital-land-python if pinned)
          if [ -f requirements.txt ]; then
            grep -v '^.*digital-land-python.*$' requirements.txt > /tmp/requirements-ci.txt || true
            pip install -r /tmp/requirements-ci.txt
          fi

          pip install pandas requests

      # Step 6: Run batch assign script (non-interactive handled by script patches)
      - name: Run batch assign entities
        env:
          CI: "true"
          GITHUB_ACTIONS: "true"
        run: |
          python bin/batch_assign_entities_single_source.py

      # Step 7: Upload outputs as artifacts (even on failure)
      - name: Upload generated outputs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: batch-assign-outputs
          path: |
            issue_summary.csv
            pipeline/**/lookup.csv
            **/*.log
          if-no-files-found: ignore

      # Step 8: Stage ONLY lookup.csv changes (under pipeline/), discard everything else
      - name: Stage lookup.csv only
        run: |
          git add pipeline/**/lookup.csv || true
          git restore --worktree -- . || true

      # Step 9: Detect whether lookup.csv changed
      - name: Check for lookup.csv changes
        id: lookup_diff
        run: |
          if git diff --cached --name-only -- 'pipeline/**/lookup.csv' | grep -q .; then
            echo "changed=true" >> "$GITHUB_OUTPUT"
          else
            echo "changed=false" >> "$GITHUB_OUTPUT"
          fi

      # Step 10: Create PR only if lookup.csv changed
      - name: Create Pull Request
        if: steps.lookup_diff.outputs.changed == 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          commit-message: "Update pipeline lookup.csv"
          title: "Update pipeline lookup.csv"
          body: |
            Automated update of `pipeline/**/lookup.csv` generated by
            `bin/batch_assign_entities_single_source.py`.

            - Non-interactive CI run
            - Uses Digital Land specification (checked out during workflow)
          branch: batch-assign-entities-single-source
          delete-branch: true
          labels: |
            automated-pr
            data
            lookup

      # Step 11: Cleanup temp files (always)
      - name: Cleanup temp files
        if: always()
        run: |
          rm -rf resource || true
          rm -rf var/cache || true
          rm -rf specification || true
